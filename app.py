import streamlit as st
import pandas as pd
import google.generativeai as genai

# à¹‚à¸«à¸¥à¸” Gemini API Key
GEMINI_API_KEY = st.secrets.get("GEMINI_API_KEY", "AIzaSyBdf4nh_jx7Jq3M8lZ4Zbfim6GULaNr9iI")  # à¹à¸à¹‰à¹ƒà¸ªà¹ˆà¸•à¸£à¸‡ à¹† à¹„à¸”à¹‰
genai.configure(api_key=GEMINI_API_KEY)

# ---------- à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ column à¸”à¹‰à¸§à¸¢ Gemini ---------- #
def generate_gemini_descriptions(df: pd.DataFrame) -> list:
    model = genai.GenerativeModel("gemini-pro")
    descriptions = []

    for col in df.columns:
        sample_values = df[col].dropna().astype(str).unique()[:5]
        prompt = f"""
You are a data analyst. Analyze the following column and provide a clear, concise description of what it likely represents.

Column name: {col}
Sample values: {', '.join(sample_values)}

Respond with just the description in one sentence.
"""
        try:
            response = model.generate_content(prompt)
            descriptions.append(response.text.strip())
        except Exception as e:
            descriptions.append(f"(Error generating description: {e})")

    return descriptions

# ---------- à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸›à¸£à¸°à¹€à¸ à¸—à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ ---------- #
def infer_column_type(series: pd.Series) -> str:
    if pd.api.types.is_datetime64_any_dtype(series):
        return "date"
    elif pd.api.types.is_integer_dtype(series):
        return "int64"
    elif pd.api.types.is_float_dtype(series):
        return "float64"
    elif pd.api.types.is_bool_dtype(series):
        return "bool"
    elif pd.api.types.is_string_dtype(series) or series.dtype == "object":
        try:
            parsed = pd.to_datetime(series, errors="coerce")
            if parsed.notna().sum() > 0:
                return "date"
            else:
                return "string"
        except:
            return "string"
    else:
        return str(series.dtype)

# ---------- à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™ Streamlit App ---------- #
st.set_page_config(page_title="CSV + Data Dictionary with Gemini", layout="wide")
st.title("ğŸ§  CSV Chatbot Assistant with Optional Data Dictionary (Gemini AI)")

tab1, tab2 = st.tabs(["ğŸ“ Upload CSV Dataset", "ğŸ“‘ Upload Data Dictionary"])

# -------------------- TAB 1: Upload CSV Dataset -------------------- #
with tab1:
    st.header("ğŸ“ Upload CSV Dataset (Required)")
    uploaded_csv = st.file_uploader("Upload your main dataset (.csv)", type=["csv"])

    if uploaded_csv:
        df = pd.read_csv(uploaded_csv)
        st.success("âœ… Dataset uploaded successfully!")
        st.subheader("ğŸ” Preview of Dataset")
        st.dataframe(df.head())
    else:
        st.info("Please upload your main CSV dataset to proceed.")

# -------------------- TAB 2: Upload or Generate Data Dictionary -------------------- #
with tab2:
    st.header("ğŸ“‘ Upload Data Dictionary (Optional)")
    uploaded_dict = st.file_uploader("Upload a data dictionary (.csv or .xlsx)", type=["csv", "xlsx"])

    if uploaded_dict:
        try:
            if uploaded_dict.name.endswith(".csv"):
                data_dict = pd.read_csv(uploaded_dict)
            else:
                data_dict = pd.read_excel(uploaded_dict)
            st.success("âœ… Data Dictionary uploaded.")
            st.subheader("ğŸ“– Uploaded Data Dictionary")
            st.dataframe(data_dict)
        except Exception as e:
            st.error(f"âŒ Error reading dictionary: {e}")

    elif 'df' in locals():
        st.warning("âš ï¸ No Data Dictionary uploaded. Generating one with Gemini AI...")

        # Generate types and descriptions
        types = [infer_column_type(df[col]) for col in df.columns]
        examples = [df[col].dropna().iloc[0] if not df[col].dropna().empty else "N/A" for col in df.columns]
        descriptions = generate_gemini_descriptions(df)

        data_dict = pd.DataFrame({
            "Column Name": df.columns,
            "Data Type": types,
            "Example Value": examples,
            "Description": descriptions
        })

        st.subheader("ğŸ¤– Gemini-Generated Data Dictionary")
        st.dataframe(data_dict)
    else:
        st.info("Please upload a dataset first in the first tab.")
